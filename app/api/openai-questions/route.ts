// app/api/openai-questions/route.ts
import { type NextRequest, NextResponse } from "next/server"
import { generateText } from "ai"
import { openai } from "@ai-sdk/openai"

// Configuration pour diff√©rents modes de vitesse
export const runtime = 'edge'
export const preferredRegion = 'auto'

// Types
interface QuestionMode {
  speed: 'fast' | 'balanced' | 'intelligent'
}

// Cache LRU simple pour les patterns fr√©quents
class SimpleCache {
  private cache = new Map<string, any>()
  private maxSize = 50

  get(key: string): any | null {
    return this.cache.get(key) || null
  }

  set(key: string, value: any): void {
    if (this.cache.size >= this.maxSize) {
      const firstKey = this.cache.keys().next().value
      this.cache.delete(firstKey)
    }
    this.cache.set(key, value)
  }
}

const patternCache = new SimpleCache()

// Patterns de diagnostic pour t√©l√©m√©decine
const DIAGNOSTIC_PATTERNS = {
  chest_pain: {
    keywords: ["thorax", "poitrine", "cardiaque", "oppression"],
    questions: [
      {
        question: "O√π ressentez-vous exactement la douleur?",
        options: [
          "Centre de la poitrine",
          "C√¥t√© gauche", 
          "Dos",
          "Partout"
        ],
        priority: "high"
      },
      {
        question: "La douleur appara√Æt-elle √† l'effort?",
        options: ["Oui", "Non", "Parfois", "Je ne sais pas"],
        priority: "high"
      }
    ]
  },
  headache: {
    keywords: ["t√™te", "c√©phal√©e", "migraine", "mal de t√™te"],
    questions: [
      {
        question: "Comment d√©cririez-vous votre mal de t√™te?",
        options: [
          "Pulsatile (battements)",
          "En √©tau",
          "Comme un coup de poignard",
          "Diffus"
        ],
        priority: "high"
      }
    ]
  }
}

// D√©tection rapide du pattern principal
function detectMainPattern(symptoms: string | undefined | null): string {
  const symptomsLower = String(symptoms || '').toLowerCase()
  
  for (const [pattern, data] of Object.entries(DIAGNOSTIC_PATTERNS)) {
    if (data.keywords.some(keyword => symptomsLower.includes(keyword))) {
      return pattern
    }
  }
  
  return 'general'
}

// G√©n√©ration de prompt selon le mode - SIMPLIFI√â
function generatePromptByMode(
  mode: string,
  patientData: any,
  clinicalData: any,
  pattern: string
): string {
  const age = patientData?.age || '√Çge inconnu'
  const gender = patientData?.gender || 'Genre non sp√©cifi√©'
  const symptoms = String(clinicalData?.symptoms || clinicalData?.chiefComplaint || 'Sympt√¥mes non sp√©cifi√©s')
  
  // Prompt TR√àS SIMPLE pour faciliter le parsing
  const simplePrompt = `Patient: ${age} ans, ${gender}. Sympt√¥mes: ${symptoms}.

G√©n√®re un JSON avec 5 questions diagnostiques. Format:
{"questions":[{"id":1,"question":"...","options":["...","...","...","..."],"priority":"high"}]}

R√©ponds UNIQUEMENT avec le JSON, rien d'autre.`

  return simplePrompt
}

// Questions de fallback pr√©-g√©n√©r√©es
const FALLBACK_QUESTIONS = {
  general: [
    {
      id: 1,
      question: "Depuis combien de temps avez-vous ces sympt√¥mes?",
      options: ["Moins de 24h", "2-7 jours", "1-4 semaines", "Plus d'un mois"],
      priority: "high"
    },
    {
      id: 2,
      question: "Comment vos sympt√¥mes √©voluent-ils?",
      options: ["S'aggravent", "Stables", "S'am√©liorent", "Varient"],
      priority: "high"
    },
    {
      id: 3,
      question: "Qu'est-ce qui d√©clenche ou aggrave vos sympt√¥mes?",
      options: ["Effort/mouvement", "Stress", "Alimentation", "Rien de particulier"],
      priority: "medium"
    },
    {
      id: 4,
      question: "Avez-vous de la fi√®vre?",
      options: ["Oui, mesur√©e >38¬∞C", "Je me sens fi√©vreux", "Non", "Je ne sais pas"],
      priority: "high"
    },
    {
      id: 5,
      question: "Votre √©tat g√©n√©ral vous inqui√®te-t-il?",
      options: ["Tr√®s inquiet", "Mod√©r√©ment", "Peu inquiet", "Pas du tout"],
      priority: "medium"
    }
  ],
  chest_pain: [
    {
      id: 1,
      question: "O√π ressentez-vous exactement la douleur?",
      options: ["Centre de la poitrine", "C√¥t√© gauche", "Dos", "Partout"],
      priority: "high"
    },
    {
      id: 2,
      question: "La douleur appara√Æt-elle √† l'effort?",
      options: ["Oui", "Non", "Parfois", "Je ne sais pas"],
      priority: "high"
    },
    {
      id: 3,
      question: "La douleur irradie-t-elle?",
      options: ["Vers le bras gauche", "Vers la m√¢choire", "Vers le dos", "Non"],
      priority: "high"
    }
  ],
  headache: [
    {
      id: 1,
      question: "Comment d√©cririez-vous votre mal de t√™te?",
      options: ["Pulsatile (battements)", "En √©tau", "Comme un coup de poignard", "Diffus"],
      priority: "high"
    },
    {
      id: 2,
      question: "Avez-vous des sympt√¥mes associ√©s?",
      options: ["Naus√©es", "Sensibilit√© √† la lumi√®re", "Troubles visuels", "Aucun"],
      priority: "high"
    }
  ]
}

// Configuration des mod√®les IA
const AI_CONFIGS = {
  fast: {
    model: "gpt-3.5-turbo",
    temperature: 0.1,
    maxTokens: 500
  },
  balanced: {
    model: "gpt-4o-mini", 
    temperature: 0.2,
    maxTokens: 800
  },
  intelligent: {
    model: "gpt-4o",
    temperature: 0.3,
    maxTokens: 1200
  }
}

// Fonction principale avec D√âBOGAGE COMPLET
export async function POST(request: NextRequest) {
  const startTime = Date.now()
  console.log("üöÄ D√©but requ√™te POST /api/openai-questions")
  
  try {
    // Parser la requ√™te
    const body = await request.json()
    console.log("üìù Body re√ßu:", JSON.stringify(body, null, 2))
    
    const { 
      patientData, 
      clinicalData, 
      mode = 'balanced'
    } = body

    // Validation des donn√©es
    if (!patientData || !clinicalData) {
      console.error("‚ùå Donn√©es manquantes")
      return NextResponse.json(
        { error: "Donn√©es patient et cliniques requises", success: false },
        { status: 400 }
      )
    }

    // Validation et normalisation des donn√©es
    const validatedPatientData = {
      age: patientData.age || 'Non sp√©cifi√©',
      gender: patientData.gender || 'Non sp√©cifi√©',
      ...patientData
    }

    const validatedClinicalData = {
      symptoms: clinicalData.symptoms || '',
      chiefComplaint: clinicalData.chiefComplaint || '',
      ...clinicalData
    }

    // V√©rifier le cache
    const symptomsString = String(validatedClinicalData.symptoms || validatedClinicalData.chiefComplaint || '')
    const cacheKey = `${symptomsString}_${validatedPatientData.age}_${validatedPatientData.gender}_${mode}`
    const cached = patternCache.get(cacheKey)
    if (cached) {
      console.log(`‚úÖ Cache hit: ${Date.now() - startTime}ms`)
      return NextResponse.json({
        ...cached,
        metadata: {
          ...cached.metadata,
          fromCache: true,
          responseTime: Date.now() - startTime
        }
      })
    }

    // D√©tecter le pattern principal
    const pattern = detectMainPattern(symptomsString)
    console.log(`üîç Pattern d√©tect√©: ${pattern}`)

    // G√©n√©rer le prompt
    const prompt = generatePromptByMode(mode, validatedPatientData, validatedClinicalData, pattern)
    console.log(`üìÑ Prompt g√©n√©r√© (${prompt.length} caract√®res)`)

    // Configuration selon le mode
    const aiConfig = AI_CONFIGS[mode as keyof typeof AI_CONFIGS] || AI_CONFIGS.balanced
    console.log(`‚öôÔ∏è Config IA: ${JSON.stringify(aiConfig)}`)

    try {
      console.log(`ü§ñ Appel OpenAI ${aiConfig.model}...`)
      const aiStartTime = Date.now()
      
      // APPEL SANS TIMEOUT pour voir le temps r√©el
      const result = await generateText({
        model: openai(aiConfig.model),
        prompt,
        temperature: aiConfig.temperature,
        maxTokens: aiConfig.maxTokens,
      })
      
      const aiTime = Date.now() - aiStartTime
      console.log(`‚úÖ R√©ponse OpenAI en ${aiTime}ms`)
      console.log(`üìÑ R√©ponse brute (${result.text.length} caract√®res):`)
      console.log(result.text.substring(0, 500) + (result.text.length > 500 ? '...' : ''))

      // Parser la r√©ponse
      let questions = []
      try {
        // Nettoyer et parser
        const cleanText = result.text.trim()
        // Essayer de parser directement
        let parsed
        try {
          parsed = JSON.parse(cleanText)
        } catch (e) {
          // Si √©chec, extraire entre { et }
          const start = cleanText.indexOf('{')
          const end = cleanText.lastIndexOf('}')
          if (start !== -1 && end !== -1) {
            const jsonPart = cleanText.substring(start, end + 1)
            parsed = JSON.parse(jsonPart)
          } else {
            throw new Error("Pas de JSON trouv√©")
          }
        }
        
        questions = parsed.questions || []
        console.log(`‚úÖ ${questions.length} questions extraites`)
        
      } catch (parseError) {
        console.error("‚ùå Erreur parsing:", parseError)
        console.error("Texte complet re√ßu:", result.text)
        throw parseError
      }

      // Valider les questions
      if (!Array.isArray(questions) || questions.length === 0) {
        throw new Error("Pas de questions valides")
      }

      // Pr√©parer la r√©ponse
      const response = {
        success: true,
        questions: questions.slice(0, 8),
        metadata: {
          mode,
          pattern,
          patientAge: validatedPatientData.age,
          responseTime: Date.now() - startTime,
          aiResponseTime: aiTime,
          fromCache: false,
          model: aiConfig.model
        }
      }

      // Mettre en cache
      patternCache.set(cacheKey, response)

      console.log(`‚úÖ Succ√®s total: ${response.metadata.responseTime}ms`)
      return NextResponse.json(response)

    } catch (error: any) {
      console.error(`‚ùå Erreur OpenAI:`, error)
      console.error("Stack:", error.stack)
      
      // Retourner fallback avec d√©tails d'erreur
      return NextResponse.json({
        success: true,
        questions: FALLBACK_QUESTIONS[pattern as keyof typeof FALLBACK_QUESTIONS] || FALLBACK_QUESTIONS.general,
        metadata: {
          mode,
          pattern,
          responseTime: Date.now() - startTime,
          fallback: true,
          fallbackReason: error.message,
          errorType: error.name,
          model: 'fallback'
        }
      })
    }

  } catch (error: any) {
    console.error("‚ùå Erreur g√©n√©rale:", error)
    return NextResponse.json(
      { 
        error: "Erreur g√©n√©ration questions",
        success: false,
        questions: FALLBACK_QUESTIONS.general,
        metadata: {
          fallback: true,
          error: error.message,
          errorType: error.name
        }
      },
      { status: 500 }
    )
  }
}

// Endpoint de test pour v√©rifier la connexion OpenAI
export async function GET(request: NextRequest) {
  console.log("üß™ Test connexion OpenAI...")
  
  try {
    // Test simple
    const testStart = Date.now()
    const result = await generateText({
      model: openai("gpt-3.5-turbo"),
      prompt: "R√©ponds uniquement avec le JSON: {\"test\":\"ok\"}",
      temperature: 0,
      maxTokens: 50,
    })
    const testTime = Date.now() - testStart
    
    return NextResponse.json({
      status: "‚úÖ OpenAI connect√©",
      responseTime: `${testTime}ms`,
      response: result.text,
      modes: {
        fast: {
          description: "Ultra-rapide",
          model: "gpt-3.5-turbo",
          useCase: "Triage initial"
        },
        balanced: {
          description: "√âquilibr√©",
          model: "gpt-4o-mini",
          useCase: "Usage standard"
        },
        intelligent: {
          description: "Intelligence maximale",
          model: "gpt-4o",
          useCase: "Cas complexes"
        }
      }
    })
  } catch (error: any) {
    console.error("‚ùå Erreur test:", error)
    return NextResponse.json({
      status: "‚ùå Erreur OpenAI",
      error: error.message,
      errorType: error.name
    }, { status: 500 })
  }
}
