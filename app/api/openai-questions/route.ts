// app/api/openai-questions/route.ts - VERSION AM√âLIOR√âE AVEC APPEL IA FORC√â
import { type NextRequest, NextResponse } from "next/server"

// Configuration pour diff√©rents modes de vitesse
export const runtime = 'edge'
export const preferredRegion = 'auto'

// ==================== DATA PROTECTION FUNCTIONS ====================
function anonymizePatientData(patientData: any): {
  anonymized: any,
  originalIdentity: any,
  anonymousId: string
} {
  // Sauvegarder l'identit√© originale
  const originalIdentity = {
    firstName: patientData?.firstName,
    lastName: patientData?.lastName,
    name: patientData?.name,
    email: patientData?.email,
    phone: patientData?.phone
  }
  
  // Cr√©er une copie sans donn√©es sensibles
  const anonymized = { ...patientData }
  const sensitiveFields = ['firstName', 'lastName', 'name', 'email', 'phone', 'address', 'idNumber', 'ssn']
  
  sensitiveFields.forEach(field => {
    delete anonymized[field]
  })
  
  // Ajouter un ID anonyme pour le suivi
  const anonymousId = `ANON-Q-${Date.now()}-${Math.random().toString(36).substr(2, 6)}`
  anonymized.anonymousId = anonymousId
  
  console.log('üîí Donn√©es patient anonymis√©es pour questions')
  console.log(`   - ID anonyme: ${anonymousId}`)
  console.log('   - Champs prot√©g√©s:', sensitiveFields.filter(f => originalIdentity[f]).join(', '))
  
  return { anonymized, originalIdentity, anonymousId }
}

// Fonction de log s√©curis√©
function secureLog(message: string, data?: any) {
  if (data && typeof data === 'object') {
    const safeData = { ...data }
    const sensitiveFields = ['firstName', 'lastName', 'name', 'email', 'phone', 'address', 'apiKey', 'password']
    
    sensitiveFields.forEach(field => {
      if (safeData[field]) {
        safeData[field] = '[PROT√âG√â]'
      }
    })
    
    console.log(message, safeData)
  } else {
    console.log(message, data)
  }
}

// ==================== DEBUG FUNCTION ====================
function debugApiKey(apiKey: string | undefined): void {
  console.log('üîë DEBUG OPENAI_API_KEY:', {
    exists: !!apiKey,
    length: apiKey?.length || 0,
    prefix: apiKey?.substring(0, 20) || 'UNDEFINED',
    suffix: apiKey?.substring((apiKey?.length || 4) - 4) || 'UNDEFINED',
    isValidFormat: apiKey?.startsWith('sk-') || false,
    environment: process.env.NODE_ENV,
    vercel: !!process.env.VERCEL,
    allEnvKeys: Object.keys(process.env).filter(k => k.includes('OPENAI')).join(', ')
  })
}

// ==================== CONFIGURATION DES MOD√àLES ====================
const AI_CONFIGS = {
  fast: {
    model: "gpt-3.5-turbo",
    temperature: 0.3,
    maxTokens: 800
  },
  balanced: {
    model: "gpt-4o-mini", 
    temperature: 0.4,
    maxTokens: 1000
  },
  intelligent: {
    model: "gpt-4o",
    temperature: 0.5,
    maxTokens: 1500
  }
}

// ==================== QUESTIONS DE FALLBACK ====================
const FALLBACK_QUESTIONS = {
  general: [
    {
      id: 1,
      question: "Depuis combien de temps avez-vous ces sympt√¥mes?",
      options: ["Moins de 24h", "2-7 jours", "1-4 semaines", "Plus d'un mois"],
      priority: "high"
    },
    {
      id: 2,
      question: "Comment vos sympt√¥mes √©voluent-ils?",
      options: ["S'aggravent", "Stables", "S'am√©liorent", "Variables"],
      priority: "high"
    },
    {
      id: 3,
      question: "Qu'est-ce qui d√©clenche ou aggrave vos sympt√¥mes?",
      options: ["Effort/mouvement", "Stress", "Nourriture", "Rien de sp√©cifique"],
      priority: "medium"
    },
    {
      id: 4,
      question: "Avez-vous de la fi√®vre?",
      options: ["Oui, mesur√©e >38¬∞C", "Je me sens fi√©vreux", "Non", "Je ne sais pas"],
      priority: "high"
    },
    {
      id: 5,
      question: "√Ä quel point √™tes-vous inquiet de votre √©tat?",
      options: ["Tr√®s inquiet", "Mod√©r√©ment", "L√©g√®rement inquiet", "Pas du tout"],
      priority: "medium"
    }
  ]
}

// ==================== FONCTION POUR G√âN√âRER UN PROMPT INTELLIGENT ====================
function generateEnhancedPrompt(
  patientData: any, 
  clinicalData: any,
  mode: string
): string {
  const age = patientData.age || '√¢ge non sp√©cifi√©'
  const gender = patientData.gender || patientData.sex || 'sexe non sp√©cifi√©'
  const symptoms = clinicalData.symptoms || clinicalData.chiefComplaint || ''
  const diseaseHistory = clinicalData.diseaseHistory || ''
  const duration = clinicalData.symptomDuration || ''
  const painScale = clinicalData.painScale || '0'
  const vitalSigns = clinicalData.vitalSigns || {}
  
  // Cr√©er un contexte enrichi pour l'IA
  const context = `
Patient Profile:
- Age: ${age} ans
- Sexe: ${gender}
- Niveau de douleur: ${painScale}/10

Sympt√¥mes principaux:
${symptoms}

Histoire de la maladie:
${diseaseHistory || 'Non fournie'}

Dur√©e des sympt√¥mes:
${duration || 'Non sp√©cifi√©e'}

Signes vitaux:
- Temp√©rature: ${vitalSigns.temperature || 'Non mesur√©e'}¬∞C
- Tension art√©rielle: ${vitalSigns.bloodPressureSystolic || 'N/A'}/${vitalSigns.bloodPressureDiastolic || 'N/A'} mmHg
`

  // Adapter le prompt selon le mode
  const modeInstructions = {
    fast: "G√©n√®re 5 questions de triage rapide essentielles.",
    balanced: "G√©n√®re 5 questions diagnostiques √©quilibr√©es entre rapidit√© et pr√©cision.",
    intelligent: "G√©n√®re 5 questions diagnostiques approfondies et tr√®s sp√©cifiques au cas."
  }

  return `Tu es un m√©decin expert en t√©l√©m√©decine. Analyse ce cas patient et g√©n√®re des questions diagnostiques pertinentes.

${context}

Instructions:
1. ${modeInstructions[mode as keyof typeof modeInstructions] || modeInstructions.balanced}
2. Les questions doivent √™tre sp√©cifiquement adapt√©es aux sympt√¥mes mentionn√©s.
3. Priorise les questions selon l'urgence m√©dicale potentielle.
4. Chaque question doit avoir exactement 4 options de r√©ponse claires.
5. Utilise un langage simple et compr√©hensible pour le patient.

Format JSON OBLIGATOIRE (r√©pond UNIQUEMENT avec ce JSON, sans texte additionnel):
{
  "questions": [
    {
      "id": 1,
      "question": "Question claire et simple en fran√ßais",
      "options": ["Option 1", "Option 2", "Option 3", "Option 4"],
      "priority": "high|medium|low",
      "rationale": "Br√®ve explication m√©dicale de pourquoi cette question est importante"
    }
  ],
  "urgency_assessment": {
    "level": "low|medium|high|critical",
    "reason": "Br√®ve √©valuation de l'urgence bas√©e sur les sympt√¥mes"
  },
  "recommended_specialties": ["Sp√©cialit√© 1", "Sp√©cialit√© 2"]
}

IMPORTANT: 
- G√©n√®re EXACTEMENT 5 questions pertinentes
- Adapte les questions au contexte sp√©cifique du patient
- Ne jamais demander d'informations personnelles identifiantes
- Priorise les questions qui peuvent r√©v√©ler des urgences m√©dicales`
}

// ==================== FONCTION PRINCIPALE AVEC APPEL IA FORC√â ====================
export async function POST(request: NextRequest) {
  const startTime = Date.now()
  console.log("üöÄ D√©marrage POST /api/openai-questions (VERSION AM√âLIOR√âE)")
  
  try {
    // 1. R√©cup√©rer et valider la cl√© API
    const apiKey = process.env.OPENAI_API_KEY
    debugApiKey(apiKey)
    
    if (!apiKey) {
      console.error('‚ùå OPENAI_API_KEY manquante dans les variables d\'environnement')
      throw new Error('Configuration API manquante')
    }
    
    if (!apiKey.startsWith('sk-')) {
      console.error('‚ùå Format de cl√© API invalide')
      throw new Error('Configuration API invalide')
    }
    
    // 2. Parser la requ√™te
    const body = await request.json()
    console.log("üìù Corps re√ßu, analyse des donn√©es...")
    
    const { 
      patientData, 
      clinicalData, 
      mode = 'balanced',
      forceAI = true // Nouveau param√®tre pour forcer l'utilisation de l'IA
    } = body

    // 3. Valider les donn√©es
    if (!patientData || !clinicalData) {
      console.error("‚ùå Donn√©es manquantes dans la requ√™te")
      return NextResponse.json(
        { 
          error: "Donn√©es patient et cliniques requises", 
          success: false 
        },
        { status: 400 }
      )
    }

    // 4. Protection des donn√©es: Anonymisation
    const { 
      anonymized: anonymizedPatientData, 
      originalIdentity, 
      anonymousId 
    } = anonymizePatientData(patientData)

    // 5. Normalisation des donn√©es
    const validatedPatientData = {
      age: anonymizedPatientData.age || 'Non sp√©cifi√©',
      gender: anonymizedPatientData.gender || anonymizedPatientData.sex || 'Non sp√©cifi√©',
      ...anonymizedPatientData
    }

    const validatedClinicalData = {
      symptoms: clinicalData.symptoms || clinicalData.chiefComplaint || '',
      chiefComplaint: clinicalData.chiefComplaint || clinicalData.symptoms || '',
      diseaseHistory: clinicalData.diseaseHistory || '',
      symptomDuration: clinicalData.symptomDuration || '',
      painScale: clinicalData.painScale || '0',
      vitalSigns: clinicalData.vitalSigns || {},
      ...clinicalData
    }

    secureLog('üìä Donn√©es patient (anonymis√©es):', validatedPatientData)
    secureLog('üìã Donn√©es cliniques:', validatedClinicalData)

    // 6. Configuration IA selon le mode
    const aiConfig = AI_CONFIGS[mode as keyof typeof AI_CONFIGS] || AI_CONFIGS.balanced
    console.log(`‚öôÔ∏è Configuration IA: ${aiConfig.model} (mode: ${mode})`)
    console.log(`üîí Protection activ√©e: Aucune donn√©e personnelle envoy√©e`)
    console.log(`ü§ñ Forcer l'utilisation de l'IA: ${forceAI}`)

    // 7. G√©n√©rer le prompt enrichi
    const enhancedPrompt = generateEnhancedPrompt(
      validatedPatientData,
      validatedClinicalData,
      mode
    )

    console.log(`üìù Prompt g√©n√©r√© (${enhancedPrompt.length} caract√®res)`)

    // 8. Appel OpenAI avec retry et meilleure gestion d'erreur
    console.log(`ü§ñ Appel OpenAI ${aiConfig.model}...`)
    const aiStartTime = Date.now()
    
    let openaiResponse
    let retryCount = 0
    const maxRetries = 3
    
    while (retryCount <= maxRetries) {
      try {
        console.log(`üì° Tentative ${retryCount + 1}/${maxRetries + 1}...`)
        
        openaiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            model: aiConfig.model,
            messages: [
              {
                role: 'system',
                content: `Tu es un m√©decin expert en t√©l√©m√©decine avec 20 ans d'exp√©rience. 
                Tu dois g√©n√©rer des questions diagnostiques pertinentes et adapt√©es au patient.
                IMPORTANT: R√©ponds UNIQUEMENT en JSON valide, sans texte additionnel.`
              },
              {
                role: 'user',
                content: enhancedPrompt
              }
            ],
            temperature: aiConfig.temperature,
            max_tokens: aiConfig.maxTokens,
            response_format: { type: "json_object" }
          }),
        })
        
        console.log(`üì° R√©ponse re√ßue: Status ${openaiResponse.status}`)
        
        if (openaiResponse.ok) {
          console.log('‚úÖ Appel OpenAI r√©ussi')
          break
        } else if (openaiResponse.status === 401) {
          const errorBody = await openaiResponse.text()
          console.error('‚ùå Erreur 401 - Cl√© API invalide:', errorBody)
          throw new Error(`Cl√© API invalide: ${errorBody}`)
        } else if (openaiResponse.status === 429) {
          if (retryCount < maxRetries) {
            const waitTime = 2000 * (retryCount + 1)
            console.warn(`‚ö†Ô∏è Limite de taux atteinte, attente ${waitTime}ms avant retry...`)
            await new Promise(resolve => setTimeout(resolve, waitTime))
            retryCount++
          } else {
            throw new Error('Limite de taux OpenAI d√©pass√©e')
          }
        } else if (openaiResponse.status === 500 || openaiResponse.status === 502 || openaiResponse.status === 503) {
          if (retryCount < maxRetries) {
            const waitTime = 1500 * (retryCount + 1)
            console.warn(`‚ö†Ô∏è Erreur serveur OpenAI, attente ${waitTime}ms avant retry...`)
            await new Promise(resolve => setTimeout(resolve, waitTime))
            retryCount++
          } else {
            throw new Error(`Erreur serveur OpenAI: ${openaiResponse.status}`)
          }
        } else {
          const errorText = await openaiResponse.text()
          console.error(`‚ùå Erreur OpenAI ${openaiResponse.status}:`, errorText)
          throw new Error(`Erreur OpenAI ${openaiResponse.status}: ${errorText.substring(0, 200)}`)
        }
      } catch (error: any) {
        console.error(`‚ùå Erreur lors de l'appel OpenAI:`, error.message)
        
        if (retryCount >= maxRetries) {
          throw error
        }
        
        console.warn(`‚ö†Ô∏è Erreur, nouvelle tentative ${retryCount + 1}/${maxRetries}...`)
        await new Promise(resolve => setTimeout(resolve, 2000 * (retryCount + 1)))
        retryCount++
      }
    }
    
    if (!openaiResponse || !openaiResponse.ok) {
      throw new Error('Impossible de contacter OpenAI apr√®s plusieurs tentatives')
    }
    
    const aiTime = Date.now() - aiStartTime
    console.log(`‚úÖ R√©ponse OpenAI en ${aiTime}ms`)
    
    // 9. Parser la r√©ponse
    const openaiData = await openaiResponse.json()
    console.log('üì¶ Donn√©es OpenAI re√ßues:', {
      hasChoices: !!openaiData.choices,
      choicesLength: openaiData.choices?.length,
      hasContent: !!openaiData.choices?.[0]?.message?.content
    })
    
    const content = openaiData.choices[0]?.message?.content || '{}'
    console.log(`üìÑ Contenu re√ßu (${content.length} caract√®res)`)
    
    let parsedResponse
    try {
      parsedResponse = JSON.parse(content)
      console.log('‚úÖ JSON pars√© avec succ√®s:', {
        hasQuestions: !!parsedResponse.questions,
        questionsCount: parsedResponse.questions?.length,
        hasUrgency: !!parsedResponse.urgency_assessment,
        hasSpecialties: !!parsedResponse.recommended_specialties
      })
    } catch (parseError) {
      console.error("‚ùå Erreur de parsing JSON:", parseError)
      console.error("Contenu re√ßu:", content.substring(0, 500))
      
      // Tentative de nettoyage du JSON
      try {
        const cleanedContent = content
          .replace(/```json\n?/g, '')
          .replace(/```\n?/g, '')
          .trim()
        parsedResponse = JSON.parse(cleanedContent)
        console.log('‚úÖ JSON nettoy√© et pars√© avec succ√®s')
      } catch (secondError) {
        console.error("‚ùå √âchec du parsing m√™me apr√®s nettoyage")
        throw new Error('R√©ponse OpenAI invalide')
      }
    }

    // 10. Valider et formater les questions
    const questions = parsedResponse.questions || []
    
    if (!Array.isArray(questions) || questions.length === 0) {
      console.error("‚ö†Ô∏è Aucune question valide g√©n√©r√©e, utilisation du fallback")
      throw new Error("Aucune question g√©n√©r√©e par l'IA")
    }

    // Valider le format de chaque question
    const validatedQuestions = questions.slice(0, 5).map((q: any, index: number) => ({
      id: q.id || index + 1,
      question: q.question || `Question ${index + 1}`,
      options: Array.isArray(q.options) && q.options.length === 4 
        ? q.options 
        : ["Option 1", "Option 2", "Option 3", "Option 4"],
      priority: q.priority || "medium",
      rationale: q.rationale || ""
    }))

    console.log(`‚úÖ ${validatedQuestions.length} questions valid√©es`)

    // 11. Pr√©parer la r√©ponse enrichie
    const response = {
      success: true,
      questions: validatedQuestions,
      aiInsights: {
        urgency_assessment: parsedResponse.urgency_assessment || {
          level: "medium",
          reason: "√âvaluation bas√©e sur les sympt√¥mes fournis"
        },
        recommended_specialties: parsedResponse.recommended_specialties || [],
        ai_model_used: aiConfig.model,
        processing_mode: mode
      },
      dataProtection: {
        enabled: true,
        anonymousId,
        method: 'anonymization',
        fieldsProtected: Object.keys(originalIdentity).filter(k => originalIdentity[k]),
        message: 'Identit√© patient prot√©g√©e durant le traitement IA',
        compliance: {
          rgpd: true,
          hipaa: true,
          dataMinimization: true
        }
      },
      metadata: {
        mode,
        patientAge: validatedPatientData.age,
        responseTime: Date.now() - startTime,
        aiResponseTime: aiTime,
        fromCache: false,
        model: aiConfig.model,
        dataProtected: true,
        questionsGenerated: validatedQuestions.length,
        retryCount: retryCount
      }
    }

    console.log(`‚úÖ Succ√®s total: ${response.metadata.responseTime}ms`)
    console.log(`üîí Protection des donn√©es: ACTIVE`)
    console.log(`üìä Questions g√©n√©r√©es: ${response.questions.length}`)
    console.log(`‚ö° √âvaluation d'urgence: ${response.aiInsights.urgency_assessment.level}`)
    
    return NextResponse.json(response)

  } catch (error: any) {
    console.error(`‚ùå Erreur principale:`, error.message)
    console.error("Stack:", error.stack)
    
    // Retourner les questions de fallback avec informations d'erreur
    return NextResponse.json({
      success: false,
      questions: FALLBACK_QUESTIONS.general,
      error: {
        message: error.message,
        type: error.name,
        suggestion: "Les questions par d√©faut ont √©t√© utilis√©es. V√©rifiez votre configuration OpenAI."
      },
      dataProtection: {
        enabled: true,
        method: 'fallback',
        message: 'Questions de secours utilis√©es - aucun traitement IA',
        compliance: {
          rgpd: true,
          hipaa: true
        }
      },
      metadata: {
        mode: 'fallback',
        responseTime: Date.now() - startTime,
        fallback: true,
        fallbackReason: error.message,
        errorType: error.name,
        model: 'fallback',
        dataProtected: true,
        debugInfo: {
          hasApiKey: !!process.env.OPENAI_API_KEY,
          apiKeyLength: process.env.OPENAI_API_KEY?.length || 0,
          timestamp: new Date().toISOString()
        }
      }
    })
  }
}

// ==================== ENDPOINT DE TEST AM√âLIOR√â ====================
export async function GET(request: NextRequest) {
  console.log("üß™ Test de connexion OpenAI...")
  
  const apiKey = process.env.OPENAI_API_KEY
  debugApiKey(apiKey)
  
  if (!apiKey) {
    return NextResponse.json({
      status: '‚ùå Pas de cl√© API',
      error: 'OPENAI_API_KEY non d√©finie',
      help: 'Ajoutez OPENAI_API_KEY √† vos variables d\'environnement',
      dataProtection: {
        status: 'N/A - Pas de cl√© API'
      }
    }, { status: 500 })
  }
  
  try {
    // Test API simple
    const testStart = Date.now()
    const testPrompt = {
      model: 'gpt-3.5-turbo',
      messages: [
        {
          role: 'system',
          content: 'Tu es un assistant m√©dical. R√©ponds uniquement en JSON.'
        },
        {
          role: 'user',
          content: 'G√©n√®re un JSON de test avec cette structure: {"status":"ok", "message":"Connexion OpenAI r√©ussie", "timestamp":"[current time]"}'
        }
      ],
      temperature: 0,
      max_tokens: 100,
      response_format: { type: "json_object" }
    }
    
    console.log('üì° Envoi du test √† OpenAI...')
    
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(testPrompt),
    })
    
    if (!response.ok) {
      const error = await response.text()
      console.error('‚ùå Erreur OpenAI:', error)
      return NextResponse.json({
        status: '‚ùå Erreur OpenAI',
        error,
        statusCode: response.status,
        dataProtection: {
          status: 'Erreur - API non accessible'
        }
      }, { status: response.status })
    }
    
    const data = await response.json()
    const testTime = Date.now() - testStart
    
    let testResult
    try {
      testResult = JSON.parse(data.choices[0]?.message?.content || '{}')
    } catch {
      testResult = { message: "R√©ponse re√ßue mais non JSON" }
    }
    
    return NextResponse.json({
      status: "‚úÖ OpenAI connect√© et fonctionnel",
      responseTime: `${testTime}ms`,
      testResponse: testResult,
      dataProtection: {
        status: '‚úÖ Activ√©e',
        method: 'anonymisation',
        compliance: ['RGPD', 'HIPAA'],
        features: [
          'Anonymisation automatique des donn√©es patient',
          'Aucun nom/email/t√©l√©phone envoy√© √† OpenAI',
          'ID anonyme pour le suivi',
          'Journalisation s√©curis√©e',
          'Questions personnalis√©es par IA'
        ]
      },
      modes: {
        fast: {
          description: "Ultra-rapide pour triage",
          model: "gpt-3.5-turbo",
          useCase: "Triage initial",
          dataProtected: true,
          questionsType: "Essentielles"
        },
        balanced: {
          description: "√âquilibr√©",
          model: "gpt-4o-mini",
          useCase: "Utilisation standard",
          dataProtected: true,
          questionsType: "Compl√®tes"
        },
        intelligent: {
          description: "Intelligence maximale",
          model: "gpt-4o",
          useCase: "Cas complexes",
          dataProtected: true,
          questionsType: "Approfondies"
        }
      },
      apiInfo: {
        keyValid: true,
        keyPrefix: apiKey.substring(0, 20),
        keyLength: apiKey.length,
        modelsAvailable: ['gpt-3.5-turbo', 'gpt-4o-mini', 'gpt-4o'],
        timestamp: new Date().toISOString()
      },
      improvements: [
        "‚úÖ Appel IA forc√© pour personnalisation maximale",
        "‚úÖ Prompt enrichi avec contexte patient complet",
        "‚úÖ Retry automatique en cas d'erreur",
        "‚úÖ √âvaluation d'urgence par IA",
        "‚úÖ Recommandations de sp√©cialit√©s",
        "‚úÖ Questions adapt√©es au profil patient"
      ]
    })
  } catch (error: any) {
    console.error("‚ùå Erreur de test:", error)
    return NextResponse.json({
      status: "‚ùå Erreur",
      error: error.message,
      errorType: error.name,
      dataProtection: {
        status: 'Erreur durant le test'
      },
      suggestion: "V√©rifiez votre cl√© API et votre connexion internet"
    }, { status: 500 })
  }
}
