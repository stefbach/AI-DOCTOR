# ğŸ” RAG EXPLIQUÃ‰ DE FAÃ‡ON ULTRA PRATIQUE

**Date**: 2 Janvier 2026  
**Pour**: Comprendre CONCRÃˆTEMENT ce qu'est le RAG

---

## ğŸ¯ RAG EN UNE PHRASE

**RAG = Google Search + GPT-4 combinÃ©s**

Au lieu de mettre TOUTES les connaissances dans le prompt, tu fais une **RECHERCHE INTELLIGENTE** pour trouver seulement les infos pertinentes, puis tu les donnes Ã  GPT-4.

---

## ğŸ“š EXEMPLE CONCRET - BibliothÃ¨que MÃ©dicale

### Situation SANS RAG (Prompt Engineering)

Tu as une **bibliothÃ¨que mÃ©dicale gÃ©ante** avec 10,000 livres :
- BNF 2024 complet
- VIDAL 2024 complet  
- ESC Guidelines 2024
- NICE Guidelines 2024
- Etc.

**Chaque fois qu'un patient arrive**, tu fais quoi?

```
âŒ SANS RAG (Prompt Engineering):
Tu photocopies LES 10,000 LIVRES et tu les donnes Ã  GPT-4

"VoilÃ  tous les livres de mÃ©decine. 
Maintenant rÃ©ponds Ã  ma question sur la pneumonie."

ProblÃ¨me:
- Trop lourd (10,000 livres!)
- Trop lent
- Trop cher
- GPT-4 doit chercher dans 10,000 livres Ã  chaque fois
```

### Situation AVEC RAG

```
âœ… AVEC RAG:
Patient avec pneumonie arrive

1. TU CHERCHES dans la bibliothÃ¨que:
   "Donne-moi les 10 livres qui parlent de pneumonie, 
    antibiotiques, et mÃ©dicaments du patient"
   
2. La bibliothÃ¨que te donne les 10 LIVRES PERTINENTS:
   - Livre sur Amoxicillin
   - Livre sur traitement pneumonie
   - Livre sur interactions mÃ©dicaments
   - 7 autres livres pertinents
   
3. Tu donnes CES 10 LIVRES Ã  GPT-4 (pas les 10,000!)

"VoilÃ  les 10 livres pertinents pour ce patient.
Maintenant rÃ©ponds Ã  ma question sur la pneumonie."

RÃ©sultat:
âœ… LÃ©ger (10 livres seulement)
âœ… Rapide
âœ… Moins cher
âœ… GPT-4 trouve rapidement l'info pertinente
```

---

## ğŸ¬ SCÃ‰NARIO PRATIQUE DÃ‰TAILLÃ‰

### Ã‰tape 1: Setup Initial (1 fois au dÃ©but)

Tu prÃ©pares ta "bibliothÃ¨que intelligente" :

```typescript
// 1. Tu as BNF 2024 complet en fichier texte
const bnf2024 = `
AMOXICILLIN
-----------
Indications: Pneumonia, UTI, Otitis media
Dosing: 500mg TDS for 5 days
Contraindications: Penicillin allergy
Interactions: Warfarin (monitor INR)
...

METFORMIN
---------
Indications: Type 2 diabetes
Dosing: Start 500mg OD, max 2g/day
Contraindications: eGFR <30
Interactions: Contrast media
...

[... 500+ autres mÃ©dicaments]
`

// 2. Tu dÃ©coupes en petits morceaux (chunks)
const chunks = [
  "AMOXICILLIN: 500mg TDS for pneumonia. Contraindicated if penicillin allergy...",
  "METFORMIN: Start 500mg OD. Contraindicated if eGFR <30...",
  "AMOXICILLIN + WARFARIN: Monitor INR closely...",
  // ... 10,000 morceaux
]

// 3. Pour chaque morceau, tu demandes Ã  OpenAI: 
//    "Transforme ce texte en vecteur de nombres"
const embedding1 = await openai.embeddings.create({
  input: "AMOXICILLIN: 500mg TDS for pneumonia..."
})
// RÃ©sultat: [0.023, -0.156, 0.891, ..., 0.445] (3072 nombres)

const embedding2 = await openai.embeddings.create({
  input: "METFORMIN: Start 500mg OD..."
})
// RÃ©sultat: [0.789, 0.234, -0.567, ..., 0.123] (3072 nombres)

// ... Pour les 10,000 morceaux

// 4. Tu stockes TOUT dans une base de donnÃ©es
await supabase.from('medical_knowledge').insert([
  {
    content: "AMOXICILLIN: 500mg TDS for pneumonia...",
    embedding: [0.023, -0.156, 0.891, ..., 0.445]
  },
  {
    content: "METFORMIN: Start 500mg OD...",
    embedding: [0.789, 0.234, -0.567, ..., 0.123]
  },
  // ... 10,000 rows
])
```

**Base de donnÃ©es aprÃ¨s setup** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Table: medical_knowledge (10,000 rows)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  id  â”‚         content              â”‚      embedding        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   1  â”‚ "AMOXICILLIN: 500mg TDS..." â”‚ [0.023, -0.156, ...]  â”‚
â”‚   2  â”‚ "METFORMIN: Start 500mg..." â”‚ [0.789, 0.234, ...]   â”‚
â”‚   3  â”‚ "NSTEMI ESC 2024: Aspirin" â”‚ [-0.445, 0.123, ...]  â”‚
â”‚  ... â”‚ ...                          â”‚ ...                   â”‚
â”‚10000 â”‚ "Warfarin interactions..."  â”‚ [0.567, -0.234, ...]  â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

C'est ta **"bibliothÃ¨que intelligente"** prÃªte Ã  l'emploi!

---

### Ã‰tape 2: Patient Arrive (Ã  chaque consultation)

**Patient**: Homme 55 ans, toux productive, fiÃ¨vre, dyspnoÃ©e

```typescript
// 1. Tu construis une question de recherche
const searchQuery = `
  Patient with cough, fever, dyspnoea.
  Suspected pneumonia.
  Current medications: Metformin 1g BD, Amlodipine 5mg OD.
  Need: antibiotic treatment, drug interactions, dosing.
`

// 2. Tu transformes cette question en vecteur
const queryEmbedding = await openai.embeddings.create({
  input: searchQuery
})
// RÃ©sultat: [0.234, -0.567, 0.123, ..., 0.789]

// 3. Tu CHERCHES dans ta base de donnÃ©es:
//    "Trouve-moi les 10 documents dont le vecteur est 
//     le PLUS PROCHE de mon vecteur de question"
const { data: relevantDocs } = await supabase
  .rpc('match_medical_documents', {
    query_embedding: [0.234, -0.567, 0.123, ..., 0.789],
    match_count: 10  // Top 10
  })

// MAGIE! La base de donnÃ©es te retourne:
relevantDocs = [
  {
    content: "AMOXICILLIN: 500mg TDS for pneumonia...",
    similarity: 0.95  // 95% similaire Ã  ta question
  },
  {
    content: "Community-acquired pneumonia: First-line Amoxicillin...",
    similarity: 0.93  // 93% similaire
  },
  {
    content: "AMOXICILLIN + METFORMIN: No significant interaction...",
    similarity: 0.88  // 88% similaire
  },
  {
    content: "Respiratory tract infections: Antibiotics...",
    similarity: 0.87
  },
  // ... 6 autres documents pertinents
]
```

**Comment Ã§a marche?**

La base de donnÃ©es compare ton vecteur question `[0.234, -0.567, ...]` avec les 10,000 vecteurs stockÃ©s et trouve les 10 PLUS PROCHES.

C'est comme si tu demandais:
> "HÃ© Google, trouve-moi les 10 pages qui ressemblent le plus Ã  ma question!"

---

### Ã‰tape 3: Construire le Prompt pour GPT-4

```typescript
// 4. Tu construis un prompt ENRICHI avec les 10 docs trouvÃ©s
const enrichedPrompt = `
Vous Ãªtes un mÃ©decin expert.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“š CONNAISSANCES MÃ‰DICALES PERTINENTES (BNF 2024)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Document 1 (95% pertinent):
${relevantDocs[0].content}

Document 2 (93% pertinent):
${relevantDocs[1].content}

Document 3 (88% pertinent):
${relevantDocs[2].content}

[... 7 autres documents]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

PATIENT:
- Age: 55 ans
- Symptoms: Toux productive, fiÃ¨vre, dyspnoÃ©e
- Current medications: Metformin 1g BD, Amlodipine 5mg OD

GÃ©nÃ©rer diagnostic complet basÃ© sur les connaissances BNF 2024 ci-dessus.
`

// 5. Tu envoies Ã  GPT-4
const response = await openai.chat.completions.create({
  model: 'gpt-4o',
  messages: [
    { role: 'system', content: enrichedPrompt },
    { role: 'user', content: 'Generate diagnosis' }
  ]
})
```

---

### Ã‰tape 4: GPT-4 GÃ©nÃ¨re le Diagnostic

GPT-4 lit les 10 documents pertinents et gÃ©nÃ¨re :

```json
{
  "diagnosis": "Community-Acquired Pneumonia (CAP)",
  "medications": [
    {
      "drug": "Amoxicillin 500mg TDS",
      "duration": "5 days",
      "source": "Per BNF 2024, first-line for CAP",
      "justification": "Mild-moderate pneumonia"
    }
  ],
  "interactions": "No significant interaction between Amoxicillin and Metformin or Amlodipine",
  "investigations": [
    {
      "test": "Chest X-ray",
      "timing": "Within 24-48 hours"
    }
  ],
  "_sources_used": [
    "BNF 2024 - Amoxicillin (95% similarity)",
    "BNF 2024 - Pneumonia Treatment (93%)",
    "BNF 2024 - Drug Interactions (88%)"
  ]
}
```

---

## ğŸ”‘ MAGIE DU RAG : LES VECTEURS

### Qu'est-ce qu'un Vecteur?

Un vecteur = Une liste de nombres qui reprÃ©sente le **SENS** d'un texte.

**Exemple**:
```
Texte: "Amoxicillin for pneumonia"
Vecteur: [0.023, -0.156, 0.891, ..., 0.445] (3072 nombres)

Texte: "Antibiotic for lung infection"
Vecteur: [0.028, -0.152, 0.887, ..., 0.441] (3072 nombres)
                   â†‘ TRÃˆS PROCHES!

Texte: "Metformin for diabetes"
Vecteur: [0.789, 0.234, -0.567, ..., 0.123] (3072 nombres)
                   â†‘ TRÃˆS DIFFÃ‰RENTS!
```

Les vecteurs de **"Amoxicillin for pneumonia"** et **"Antibiotic for lung infection"** sont PROCHES car ils ont le mÃªme SENS, mÃªme si les mots sont diffÃ©rents!

### Comment OpenAI CrÃ©e les Vecteurs?

OpenAI a un modÃ¨le spÃ©cialisÃ© appelÃ© **`text-embedding-3-large`** qui lit du texte et le transforme en vecteur.

```typescript
const result = await openai.embeddings.create({
  model: 'text-embedding-3-large',
  input: "Amoxicillin 500mg TDS for pneumonia"
})

console.log(result.data[0].embedding)
// â†’ [0.023, -0.156, 0.891, ..., 0.445] (3072 nombres)
```

Ce modÃ¨le a Ã©tÃ© entraÃ®nÃ© sur des MILLIARDS de textes pour comprendre le sens des mots.

---

## ğŸ® ANALOGIE JEUX VIDÃ‰O

Imagine un jeu vidÃ©o oÃ¹ chaque personnage a des **coordonnÃ©es 3D** (x, y, z) :

```
Guerrier:    (10, 20, 5)
Chevalier:   (12, 22, 6)  â† PROCHE du guerrier
Mage:        (80, 15, 90) â† LOIN du guerrier
```

Si tu cherches "des personnages proches du guerrier", tu trouves le Chevalier (coordonnÃ©es proches).

**RAG c'est pareil, mais avec 3072 dimensions au lieu de 3!**

```
"Amoxicillin":         [0.023, -0.156, ..., 0.445] (3072 nombres)
"Antibiotic":          [0.028, -0.152, ..., 0.441] â† PROCHE
"Insulin for diabetes": [0.789, 0.234, ..., 0.123] â† LOIN
```

Recherche = Trouver les vecteurs les PLUS PROCHES dans l'espace Ã  3072 dimensions.

---

## ğŸ’» CODE COMPLET PRATIQUE

### Setup (1 fois)

```typescript
// setup-rag.ts
import { createClient } from '@supabase/supabase-js'
import { OpenAI } from 'openai'
import fs from 'fs'

const supabase = createClient(
  process.env.SUPABASE_URL,
  process.env.SUPABASE_KEY
)

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
})

async function setupRAG() {
  console.log('ğŸ“š Loading BNF 2024...')
  const bnf2024 = fs.readFileSync('data/bnf-2024.txt', 'utf8')
  
  console.log('âœ‚ï¸ Splitting into chunks...')
  const chunks = splitIntoChunks(bnf2024, 500) // 500 mots par chunk
  // RÃ©sultat: ~10,000 chunks
  
  console.log(`ğŸ“„ Total chunks: ${chunks.length}`)
  
  for (let i = 0; i < chunks.length; i++) {
    console.log(`ğŸ”„ Processing chunk ${i+1}/${chunks.length}...`)
    
    // CrÃ©er embedding
    const embeddingResponse = await openai.embeddings.create({
      model: 'text-embedding-3-large',
      input: chunks[i]
    })
    
    const embedding = embeddingResponse.data[0].embedding
    
    // Stocker dans Supabase
    await supabase
      .from('medical_knowledge')
      .insert({
        content: chunks[i],
        source: 'BNF 2024',
        embedding: embedding
      })
    
    // Rate limiting
    if (i % 100 === 0) {
      await sleep(2000) // Pause 2s tous les 100 chunks
    }
  }
  
  console.log('âœ… RAG setup complete!')
}

function splitIntoChunks(text: string, wordsPerChunk: number) {
  const words = text.split(/\s+/)
  const chunks: string[] = []
  
  for (let i = 0; i < words.length; i += wordsPerChunk) {
    const chunk = words.slice(i, i + wordsPerChunk).join(' ')
    chunks.push(chunk)
  }
  
  return chunks
}

setupRAG()
```

**ExÃ©cution**:
```bash
$ ts-node setup-rag.ts

ğŸ“š Loading BNF 2024...
âœ‚ï¸ Splitting into chunks...
ğŸ“„ Total chunks: 10,000
ğŸ”„ Processing chunk 1/10,000...
ğŸ”„ Processing chunk 2/10,000...
...
âœ… RAG setup complete!

Time: 2-4 hours
Cost: ~$20 (embeddings)
```

---

### Utilisation (Ã  chaque patient)

```typescript
// app/api/openai-diagnosis/route.ts
import { createClient } from '@supabase/supabase-js'
import { OpenAI } from 'openai'

const supabase = createClient(
  process.env.SUPABASE_URL,
  process.env.SUPABASE_KEY
)

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
})

export async function POST(request: Request) {
  const { patientData } = await request.json()
  
  // 1. Construire query de recherche
  const searchQuery = `
    Patient with ${patientData.symptoms.join(', ')}.
    Current medications: ${patientData.current_medications.join(', ')}.
    Need: diagnosis, treatment, interactions.
  `
  
  console.log('ğŸ” Searching relevant knowledge...')
  
  // 2. CrÃ©er embedding de la query
  const queryEmbedding = await openai.embeddings.create({
    model: 'text-embedding-3-large',
    input: searchQuery
  })
  
  // 3. Rechercher documents pertinents
  const { data: relevantDocs } = await supabase
    .rpc('match_medical_documents', {
      query_embedding: queryEmbedding.data[0].embedding,
      match_threshold: 0.78,  // SimilaritÃ© min 78%
      match_count: 10         // Top 10
    })
  
  console.log(`âœ… Found ${relevantDocs.length} relevant documents`)
  
  // 4. Construire prompt enrichi
  const enrichedPrompt = `
You are an expert physician.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“š RELEVANT MEDICAL KNOWLEDGE (BNF 2024)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

${relevantDocs.map((doc, i) => `
Document ${i + 1} (${(doc.similarity * 100).toFixed(1)}% relevant):
${doc.content}
`).join('\n')}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

PATIENT:
${JSON.stringify(patientData, null, 2)}

Generate complete diagnosis based on BNF 2024 knowledge above.
`
  
  // 5. Appeler GPT-4
  console.log('ğŸ¤– Generating diagnosis...')
  
  const response = await openai.chat.completions.create({
    model: 'gpt-4o',
    messages: [
      { role: 'system', content: enrichedPrompt },
      { role: 'user', content: 'Generate diagnosis' }
    ],
    max_tokens: 4000,
    temperature: 0.3
  })
  
  const diagnosis = JSON.parse(response.choices[0].message.content)
  
  // 6. Ajouter mÃ©tadonnÃ©es
  return Response.json({
    ...diagnosis,
    _metadata: {
      sources_used: relevantDocs.map(doc => ({
        source: doc.source,
        similarity: (doc.similarity * 100).toFixed(1) + '%'
      })),
      documents_retrieved: relevantDocs.length
    }
  })
}
```

**Logs d'exÃ©cution**:
```
ğŸ” Searching relevant knowledge...
âœ… Found 10 relevant documents
ğŸ¤– Generating diagnosis...
âœ… Diagnosis generated

Time: 51-71s (50-70s GPT-4 + 100ms retrieval)
```

---

## ğŸ“Š COMPARAISON PRATIQUE

### ScÃ©nario: Patient avec Pneumonie

#### Sans RAG (Prompt Engineering)

```typescript
const prompt = `
${ENTIRE_BNF_2024}  // 500 KB de texte!
${ENTIRE_ESC_2024}  // 100 KB de texte!
${ENTIRE_VIDAL_2024} // 300 KB de texte!
// Total: 900 KB dans le prompt

Patient with pneumonia...
`

// ProblÃ¨me:
// - Prompt trop grand (limite GPT-4 = 128K tokens â‰ˆ 500 KB)
// - CoÃ»t: 80K tokens Ã— $5/1M = $0.40 par patient
// - GPT-4 doit chercher dans 900 KB Ã  chaque fois
```

#### Avec RAG

```typescript
// 1. Recherche (100ms)
const relevantDocs = await searchVectorDB(
  "patient with pneumonia, need antibiotics"
)
// Trouve: 10 documents pertinents (15 KB)

// 2. Prompt
const prompt = `
${relevantDocs[0]}  // Amoxicillin info
${relevantDocs[1]}  // Pneumonia treatment
${relevantDocs[2]}  // Drug interactions
... 7 autres docs pertinents
// Total: 15 KB dans le prompt (vs 900 KB!)

Patient with pneumonia...
`

// Avantages:
// âœ… Prompt petit (15 KB < 500 KB limite)
// âœ… CoÃ»t: 5K tokens Ã— $5/1M = $0.025 par patient (16Ã— moins cher!)
// âœ… GPT-4 cherche dans 15 KB seulement
// âœ… Infos pertinentes ciblÃ©es
```

---

## ğŸ¯ EN RÃ‰SUMÃ‰ PRATIQUE

**RAG = 3 Ã©tapes simples**

### 1. SETUP (1 fois, 8-16h)
```
BNF/VIDAL/ESC â†’ DÃ©couper en chunks â†’ CrÃ©er embeddings â†’ Stocker dans DB
```

### 2. RECHERCHE (Ã  chaque patient, 100ms)
```
Question patient â†’ CrÃ©er embedding â†’ Chercher dans DB â†’ Top 10 docs pertinents
```

### 3. DIAGNOSTIC (Ã  chaque patient, 50-70s)
```
10 docs pertinents + Patient â†’ GPT-4 â†’ Diagnostic avec sources BNF 2024
```

---

## ğŸ’¡ POINTS CLÃ‰S Ã€ RETENIR

1. **RAG = Recherche Intelligente + GPT-4**
   - Tu ne donnes PAS tout le BNF Ã  GPT-4
   - Tu CHERCHES les 10 pages pertinentes
   - Tu donnes CES 10 pages Ã  GPT-4

2. **Les Vecteurs = Le Secret**
   - Chaque texte â†’ Vecteur de 3072 nombres
   - Textes similaires â†’ Vecteurs proches
   - Recherche = Trouver vecteurs les plus proches

3. **Avantages Pratiques**
   - âœ… Prompt petit (15 KB vs 900 KB)
   - âœ… Moins cher (16Ã— moins de tokens)
   - âœ… Plus rapide
   - âœ… Infos pertinentes ciblÃ©es
   - âœ… Connaissances complÃ¨tes (BNF/VIDAL entiers)

---

**Repository**: https://github.com/stefbach/AI-DOCTOR  
**Commit**: Ã€ venir  
**Status**: Explication pratique complÃ¨te

ğŸ” **RAG = Google Search pour les connaissances mÃ©dicales de GPT-4** ğŸ”
